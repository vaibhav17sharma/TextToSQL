#!/usr/bin/env python3
import subprocess
import sys
import os

def check_cuda_available():
    """Check if CUDA is available on the system"""
    # Check environment variables first
    if os.environ.get('NVIDIA_VISIBLE_DEVICES') == 'all':
        print("üåç NVIDIA_VISIBLE_DEVICES=all detected")
        return True
    
    try:
        # Check nvidia-smi command
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            print("‚úÖ nvidia-smi available")
            return True
        else:
            print("‚ùå nvidia-smi failed")
            return False
    except (FileNotFoundError, subprocess.TimeoutExpired):
        print("‚ùå nvidia-smi not found or timeout")
        return False

def install_llama_cpp():
    """Install appropriate version of llama-cpp-python"""
    if check_cuda_available():
        print("üöÄ CUDA detected, building with CUDA support...")
        try:
            # Set environment for CUDA build
            env = os.environ.copy()
            env['CMAKE_ARGS'] = '-DLLAMA_CUBLAS=ON'
            env['FORCE_CMAKE'] = '1'
            
            # Uninstall existing version first
            subprocess.run([sys.executable, "-m", "pip", "uninstall", "llama-cpp-python", "-y"], 
                         capture_output=True)
            
            subprocess.check_call([
                sys.executable, "-m", "pip", "install", 
                "llama-cpp-python==0.2.20", 
                "--force-reinstall", 
                "--no-cache-dir",
                "--no-binary=llama-cpp-python"  # Force compilation
            ], env=env)
            print("‚úÖ CUDA-enabled llama-cpp-python built successfully")
        except subprocess.CalledProcessError as e:
            print(f"‚ö†Ô∏è CUDA build failed: {e}")
            print("Installing CPU version...")
            install_cpu_version()
    else:
        print("üíª No CUDA detected, installing CPU version...")
        install_cpu_version()

def install_cpu_version():
    """Install CPU-only version"""
    subprocess.check_call([
        sys.executable, "-m", "pip", "install", 
        "llama-cpp-python==0.2.20", 
        "--force-reinstall", 
        "--no-cache-dir"
    ])
    print("‚úÖ CPU-only llama-cpp-python installed successfully")

if __name__ == "__main__":
    install_llama_cpp()